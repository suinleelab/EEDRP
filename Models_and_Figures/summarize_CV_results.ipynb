{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "cmap=plt.cm.tab20\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years_data = 2\n",
    "only_one = False\n",
    "simplify_apoe = True\n",
    "COLS_TO_USE_DICT = {\"demographic_cols_allyears\": ['dcfdx__1.0','dcfdx__2.0', 'dcfdx__3.0', 'med_con_sum_cum', 'vasc_3dis_sum',\n",
    "                            'vasc_risks_sum', 'hypertension_cum', 'cancer_cum', 'diabetes_sr_rx', 'dm_cum',\n",
    "                            'headinjrloc_cum', 'thyroid_cum', 'claudication_cum', 'heart_cum', 'stroke_cum'],\n",
    "\"demographic_cols_oneyear\": ['apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0', 'apoe_genotype__33.0', \n",
    "                            'apoe_genotype__34.0', 'apoe_genotype__44.0', 'race__1.0', 'race__2.0', 'race__3.0', \n",
    "                            'race__6.0', 'age_at_visit', 'educ', 'msex', 'spanish'],\n",
    "\n",
    "\"baseline_demographics_cols\":['age_at_visit', 'educ', 'msex', 'apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
    "                              'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0'],\n",
    "\"baseline_mci_cols\":['dcfdx__2.0', 'dcfdx__3.0'],\n",
    "\"baseline_mmse30_cols\":['age_at_visit', 'educ', 'msex', 'apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
    "                        'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0', 'cts_mmse30'],\n",
    "\"simplified_cols\":['age_at_visit', 'educ', 'msex', 'apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
    "                   'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0', \n",
    "                   'cts_catflu', 'cts_mmse30', 'cts_sdmt', 'cts_wli', 'cts_wlii', 'cts_wliii'],\n",
    "\"nocogn_cols\":['age_at_visit', 'educ', 'msex', 'apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
    "            'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0', 'spanish', \n",
    "            'race__1.0', 'race__2.0', 'race__3.0', 'race__6.0', 'dcfdx__1.0', 'dcfdx__2.0',  'dcfdx__3.0', \n",
    "            'med_con_sum_cum', 'vasc_3dis_sum', 'vasc_risks_sum', 'hypertension_cum', 'cancer_cum', 'diabetes_sr_rx', \n",
    "            'dm_cum', 'headinjrloc_cum', 'thyroid_cum', 'claudication_cum', 'heart_cum', 'stroke_cum',\n",
    "            'cts_animals', 'cts_bname', 'cts_catflu', 'cts_db', 'cts_delay', 'cts_df', 'cts_doperf', 'cts_ebdr', 'cts_ebmt', \n",
    "            'cts_fruits', 'cts_idea', 'cts_lopair', 'cts_mmse30', 'cts_nccrtd', 'cts_pmat', 'cts_pmsub', 'cts_read_nart', \n",
    "            'cts_sdmt', 'cts_story', 'cts_stroop_cname', 'cts_stroop_wread', 'cts_wli', 'cts_wlii', 'cts_wliii'],\n",
    "\"all_cols\":['age_at_visit', 'educ', 'msex', 'apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
    "            'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0', 'spanish', \n",
    "            'race__1.0', 'race__2.0', 'race__3.0', 'race__6.0', 'dcfdx__1.0', 'dcfdx__2.0',  'dcfdx__3.0', \n",
    "            'med_con_sum_cum', 'vasc_3dis_sum', 'vasc_risks_sum', 'hypertension_cum', 'cancer_cum', 'diabetes_sr_rx', \n",
    "            'dm_cum', 'headinjrloc_cum', 'thyroid_cum', 'claudication_cum', 'heart_cum', 'stroke_cum',\n",
    "            'cts_animals', 'cts_bname', 'cts_catflu', 'cts_db', 'cts_delay', 'cts_df', 'cts_doperf', 'cts_ebdr', 'cts_ebmt', \n",
    "            'cts_fruits', 'cts_idea', 'cts_lopair', 'cts_mmse30', 'cts_nccrtd', 'cts_pmat', 'cts_pmsub', 'cts_read_nart', \n",
    "            'cts_sdmt', 'cts_story', 'cts_stroop_cname', 'cts_stroop_wread', 'cts_wli', 'cts_wlii', 'cts_wliii',\n",
    "            'cogn_ep', 'cogn_po', 'cogn_ps', 'cogn_se', 'cogn_wo', 'cogn_global']}\n",
    "\n",
    "# Change depending on which test you want to run\n",
    "cols_name = 'nocogn_cols'\n",
    "cols_to_use = COLS_TO_USE_DICT[cols_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_metrics = [\"accuracy\",\"roc_auc\"]\n",
    "\n",
    "years = 2\n",
    "within = 3\n",
    "models = [\"linear\", \"xgb\",\"LSTM\", \"MLP\"]\n",
    "num_years_datas =[\"1\",\"2\",\"3\", \"ma\", \"slopes\"]\n",
    "\n",
    "sample_types = [\"randdownsample\", \"matcheddownsample\", \"train\", \"weighted\"]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    results_dict[model] = {}\n",
    "    for sample_type in sample_types:\n",
    "        results_dict[model][sample_type] = {}\n",
    "\n",
    "        for num_years_data in num_years_datas:\n",
    "            res_dicts = []\n",
    "            for k in range(5):\n",
    "\n",
    "                sample_type_prefix = \"\" if sample_type in [\"train\", \"weighted\"] else \"%s_\"%sample_type\n",
    "                sample_type_save = \"\" if sample_type==\"train\" else \"%s_\"%sample_type\n",
    "\n",
    "                save_suffix = '%s%s_%iyrprev_within%i_yrsincluded%s'%(sample_type_save, cols_name, years, within, num_years_data)\n",
    "\n",
    "                results_path = './results/CV/%s_%i_%s.p'%(model,k,save_suffix)\n",
    "\n",
    "\n",
    "                if os.path.exists(results_path):\n",
    "                    file = pickle.load(open(results_path, 'rb'))\n",
    "                    res_dict = {}\n",
    "                    res_dict['accuracy'], res_dict['roc_auc'], res_dict['pr_auc'], res_dict['precision'],  res_dict['recall'], res_dict['fpr'], res_dict['tpr'] = file\n",
    "                    res_dicts.append(res_dict)\n",
    "                    no_results = False\n",
    "                else:\n",
    "                    no_results = True\n",
    "\n",
    "            results_dict[model][sample_type][num_years_data] = {}\n",
    "\n",
    "            if no_results:\n",
    "                for eval_metric in eval_metrics:\n",
    "                    results_dict[model][sample_type][num_years_data][eval_metric] = np.nan\n",
    "\n",
    "            else:\n",
    "                for eval_metric in eval_metrics:\n",
    "                    results_dict[model][sample_type][num_years_data][eval_metric] = np.mean([r[eval_metric] for r in res_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict({(i,j,k): results_dict[i][j][k]\n",
    "                           for i in results_dict.keys() \n",
    "                           for j in results_dict[i].keys()\n",
    "                           for k in results_dict[i][j].keys()},\n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names_official = {\"linear\": \"LR\", \"LSTM\": \"LSTM\", \"MLP\": \"MLP\", \"xgb\":\"GBM\"}\n",
    "\n",
    "# appendix version\n",
    "encoding_names = {\"3\": \"All data: last 3 years\", \"2\": \"All data: last 2 years\",\n",
    "                  \"1\":\"All data: current year\", \"ma\": \"Moving averages\", \"slopes\": \"Slopes\"}\n",
    "# main text version\n",
    "sample_type_names = {\"randdownsample\": \"Random\", \"matcheddownsample\": \"Matched pairs\", \"train\": \"Original\", \n",
    "                     \"weighted\": \"Re-weighting\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate latex tables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Slopes & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Moving averages & $nan$ & $nan$ \\\\\n",
      "LSTM & Slopes & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Moving averages & $nan$ & $nan$ \\\\\n",
      "LSTM & Slopes & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Moving averages & $nan$ & $nan$ \\\\\n",
      "LSTM & Slopes & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Moving averages & $nan$ & $nan$ \\\\\n",
      "LSTM & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Slopes & $nan$ & $nan$ \\\\\n"
     ]
    }
   ],
   "source": [
    "# main text version\n",
    "for index, row in results_df.sort_values(\"accuracy\", ascending=False).iterrows():\n",
    "    model, sample_type, years_method = index\n",
    "    \n",
    "    # main text version\n",
    "    print(\"%s & %s & $%.4f$ & $%.4f$ \\\\\\\\\"%(model_names_official[model], encoding_names[years_method], row[\"accuracy\"],row[\"roc_auc\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR & Random & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & Random & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & Random & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Random & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Random & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & Matched pairs & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & Matched pairs & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & Matched pairs & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Matched pairs & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Matched pairs & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & Original & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & Original & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & Original & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Original & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Original & Slopes & $nan$ & $nan$ \\\\\n",
      "LR & Re-weighting & All data: current year & $nan$ & $nan$ \\\\\n",
      "LR & Re-weighting & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LR & Re-weighting & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LR & Re-weighting & Moving averages & $nan$ & $nan$ \\\\\n",
      "LR & Re-weighting & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & Random & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & Random & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & Random & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Random & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Random & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & Matched pairs & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & Matched pairs & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & Matched pairs & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Matched pairs & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Matched pairs & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & Original & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & Original & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & Original & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Original & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Original & Slopes & $nan$ & $nan$ \\\\\n",
      "GBM & Re-weighting & All data: current year & $nan$ & $nan$ \\\\\n",
      "GBM & Re-weighting & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "GBM & Re-weighting & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "GBM & Re-weighting & Moving averages & $nan$ & $nan$ \\\\\n",
      "GBM & Re-weighting & Slopes & $nan$ & $nan$ \\\\\n",
      "LSTM & Random & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & Random & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Random & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Matched pairs & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & Matched pairs & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Matched pairs & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Original & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & Original & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Original & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Re-weighting & All data: current year & $nan$ & $nan$ \\\\\n",
      "LSTM & Re-weighting & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "LSTM & Re-weighting & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Random & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & Random & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & Random & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Random & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Random & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & Matched pairs & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & Matched pairs & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & Matched pairs & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Matched pairs & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Matched pairs & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & Original & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & Original & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & Original & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Original & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Original & Slopes & $nan$ & $nan$ \\\\\n",
      "MLP & Re-weighting & All data: current year & $nan$ & $nan$ \\\\\n",
      "MLP & Re-weighting & All data: last 2 years & $nan$ & $nan$ \\\\\n",
      "MLP & Re-weighting & All data: last 3 years & $nan$ & $nan$ \\\\\n",
      "MLP & Re-weighting & Moving averages & $nan$ & $nan$ \\\\\n",
      "MLP & Re-weighting & Slopes & $nan$ & $nan$ \\\\\n"
     ]
    }
   ],
   "source": [
    "# appendix version\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    model, sample_type, years_method = index\n",
    "\n",
    "    if (model != \"LSTM\") or (years_method not in [\"ma\", \"slopes\"]):\n",
    "        print(\"%s & %s & %s & $%.4f$ & $%.4f$ \\\\\\\\\"%(model_names_official[model], sample_type_names[sample_type],\n",
    "                                                 encoding_names[years_method], row[\"accuracy\"],row[\"roc_auc\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing performance for single years (not cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_metrics = [\"accuracy\",\"roc_auc\", \"pr_auc\"]\n",
    "\n",
    "years = 2\n",
    "within = 3\n",
    "\n",
    "models = [\"MLP\", \"LSTM\", \"linear\",\"xgb\"]\n",
    "\n",
    "single_years = [\"yrsincluded1\", \"singleyear-1\", \"singleyear-2\"]\n",
    "multiple_years = [\"yrsincluded1\", \"yrsincluded2\", \"yrsincluded3\"]\n",
    "sample_types = [\"train\"]\n",
    "\n",
    "\n",
    "results_dict = {}\n",
    "results_dict_stderrs = {}\n",
    "\n",
    "for model in models:\n",
    "    results_dict[model] = {}\n",
    "    results_dict_stderrs[model] = {}\n",
    "\n",
    "    for sample_type in sample_types:\n",
    "        results_dict[model][sample_type] = {}\n",
    "        results_dict_stderrs[model][sample_type] = {}\n",
    "\n",
    "        for single_year in single_years+multiple_years:\n",
    "            res_dicts = []\n",
    "            for k in range(5):\n",
    "\n",
    "                sample_type_prefix = \"\" if sample_type in [\"train\", \"weighted\"] else \"%s_\"%sample_type\n",
    "                sample_type_save = \"\" if sample_type==\"train\" else \"%s_\"%sample_type\n",
    "\n",
    "                save_suffix = '%s%s_%iyrprev_within%i_%s'%(sample_type_save, cols_name, years, within, single_year)\n",
    "\n",
    "                results_path = './results/CV/%s_%i_%s.p'%(model,k,save_suffix)\n",
    "\n",
    "                if os.path.exists(results_path):\n",
    "                    file = pickle.load(open(results_path, 'rb'))\n",
    "                    res_dict = {}\n",
    "                    res_dict['accuracy'], res_dict['roc_auc'], res_dict['pr_auc'], res_dict['precision'],  res_dict['recall'], res_dict['fpr'], res_dict['tpr'] = file\n",
    "                    res_dicts.append(res_dict)\n",
    "                    no_results = False\n",
    "                else:\n",
    "                    no_results = True\n",
    "\n",
    "            results_dict[model][sample_type][single_year] = {}\n",
    "            results_dict_stderrs[model][sample_type][single_year] = {}\n",
    "\n",
    "            if no_results:\n",
    "                for eval_metric in eval_metrics:\n",
    "                    results_dict[model][sample_type][single_year][eval_metric] = np.nan\n",
    "                    results_dict_stderrs[model][sample_type][single_year][eval_metric] = np.nan\n",
    "\n",
    "            else:\n",
    "                for eval_metric in eval_metrics:\n",
    "                    results_dict[model][sample_type][single_year][eval_metric] = np.mean([r[eval_metric] for r in res_dicts])\n",
    "                    results_dict_stderrs[model][sample_type][single_year][eval_metric] = stats.sem([r[eval_metric] for r in res_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results/CV/xgb_4_nocogn_cols_2yrprev_within3_yrsincluded3.p'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan] [0, 1, 2] [nan, nan, nan]\n",
      "[nan, nan, nan] [0, 1, 2] [nan, nan, nan]\n",
      "[nan, nan, nan] [0, 1, 2] [nan, nan, nan]\n",
      "[nan, nan, nan] [0, 1, 2] [nan, nan, nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x271d1b6af28>,\n",
       "  <matplotlib.axis.XTick at 0x271d1b6aef0>,\n",
       "  <matplotlib.axis.XTick at 0x271d1b6ab38>],\n",
       " <a list of 3 Text major ticklabel objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGkCAYAAAA2ZfEBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_type = \"train\"\n",
    "eval_metric = \"roc_auc\"\n",
    "eval_metric = \"pr_auc\"\n",
    "eval_metric = \"accuracy\"\n",
    "\n",
    "models_colors = {\"MLP\": cmaplist[4], \"LSTM\": cmaplist[8], \"xgb\":cmaplist[0] , \"linear\":cmaplist[2]}\n",
    "\n",
    "to_plot_xs = [0,1,2]\n",
    "\n",
    "names = [\"yrsincluded1\", \"yrsincluded2\", \"yrsincluded3\"]\n",
    "\n",
    "f,ax =  plt.subplots(figsize=(8,6))\n",
    "# changed size to fit in 3 plots\n",
    "# f,ax =  plt.subplots(figsize=(5,7))\n",
    "\n",
    "\n",
    "for modelnum, model in enumerate(models):\n",
    "    to_plot_xs_forplot = [x+.02*modelnum for x in to_plot_xs]\n",
    "    to_plot_ys = []\n",
    "    to_plot_stderrs=[]\n",
    "    for x in to_plot_xs:\n",
    "        to_plot_ys.append(results_dict[model][sample_type][names[x]][eval_metric])\n",
    "        to_plot_stderrs.append(results_dict_stderrs[model][sample_type][names[x]][eval_metric])\n",
    "\n",
    "    color = models_colors[model]\n",
    "\n",
    "    for i in range(len(to_plot_xs)):\n",
    "        plt.errorbar(to_plot_xs_forplot[i], to_plot_ys[i], yerr=to_plot_stderrs[i], xerr=None, fmt='', ecolor=color, elinewidth=None, capsize=2, alpha=.5)\n",
    "\n",
    "    plt.plot(to_plot_xs_forplot, to_plot_ys,  c=color)\n",
    "    plt.scatter(to_plot_xs_forplot, to_plot_ys,  c=color, s=150, alpha=.8)\n",
    "\n",
    "    \n",
    "names = [\"yrsincluded1\", \"singleyear-1\", \"singleyear-2\"]\n",
    "\n",
    "\n",
    "for modelnum, model in enumerate(models):\n",
    "    to_plot_xs_forplot = [x+.02*modelnum for x in to_plot_xs]\n",
    "    to_plot_ys = []\n",
    "    to_plot_stderrs = []\n",
    "    for x in to_plot_xs:\n",
    "        to_plot_ys.append(results_dict[model][sample_type][names[x]][eval_metric])\n",
    "        to_plot_stderrs.append(results_dict_stderrs[model][sample_type][names[x]][eval_metric])\n",
    "\n",
    "    print(to_plot_ys, to_plot_xs, to_plot_stderrs)\n",
    "    \n",
    "    color = models_colors[model]\n",
    "\n",
    "    plt.plot(to_plot_xs_forplot, to_plot_ys, alpha=.5, linestyle=\"--\", c=color)\n",
    "    plt.scatter(to_plot_xs_forplot, to_plot_ys, marker=\"v\",  c=color, s=100, alpha=.8)\n",
    "\n",
    "    for i in range(len(to_plot_xs_forplot)):\n",
    "        plt.errorbar(to_plot_xs_forplot[i], to_plot_ys[i], yerr=to_plot_stderrs[i], xerr=None, fmt='', ecolor=color, elinewidth=None, capsize=2, alpha=.5)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_facecolor(\"None\")\n",
    "\n",
    "plt.legend(models, loc=(1,1))\n",
    "plt.ylabel(eval_metric)\n",
    "plt.xticks(to_plot_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
