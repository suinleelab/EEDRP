{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load  Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_folder =\"../DATA/PROCESSED/\"\n",
    "new_folder = \"../DATA/PROCESSED/standardized/\"\n",
    "\n",
    "if not os.path.isdir(new_folder):\n",
    "    os.makedirs(new_folder)\n",
    "    \n",
    "y = 2\n",
    "within = 3\n",
    "\n",
    "# current year's features -- all standardization will be based on current year\n",
    "cur_year_fname = \"merged_kept_data_%iyrprev_within%i.csv\"%(y,within)\n",
    "CURRENT_YEAR = pd.read_csv(orig_folder + cur_year_fname)\n",
    "\n",
    "# all years features - these will be used when we train multiple years of data\n",
    "all_years_fname = \"merged_data_all_%iyrprev_within%i.csv\"%(y,within)\n",
    "ALL_YEARS=pd.read_csv(orig_folder + all_years_fname)\n",
    "\n",
    "\n",
    "# merge in non-temporal demographic info \n",
    "DEMOGRAPHICS = pd.read_csv(\"../DATA/raw/dataset_495_basic.csv\")[[\"projid\", \"educ\", \"msex\", \"apoe_genotype\", \"race\", \"spanish\"]].drop_duplicates()\n",
    "DEMOGRAPHICS[\"spanish\"] = 2-DEMOGRAPHICS[\"spanish\"] \n",
    "ALL_YEARS.drop([\"educ\", \"msex\", \"apoe_genotype\", \"race\", \"spanish\"], axis=1, inplace=True)\n",
    "CURRENT_YEAR.drop([\"educ\", \"msex\", \"apoe_genotype\", \"race\", \"spanish\"], axis=1, inplace=True)\n",
    "\n",
    "ALL_YEARS = ALL_YEARS.merge(DEMOGRAPHICS, how=\"left\", on=\"projid\")\n",
    "CURRENT_YEAR = CURRENT_YEAR.merge(DEMOGRAPHICS, how=\"left\", on=\"projid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24565, 60) (9103, 60)\n"
     ]
    }
   ],
   "source": [
    "print(ALL_YEARS.shape, CURRENT_YEAR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIABLES WITH MISSING VALUES: FRACTION MISSING\n",
      "r_cistrk: 0.18\n",
      "r_stroke: 0.22\n",
      "cts_stroop_cname: 0.65\n",
      "cts_stroop_wread: 0.65\n",
      "lostcons: 0.96\n",
      "chf_cum: 0.70\n"
     ]
    }
   ],
   "source": [
    "print(\"VARIABLES WITH MISSING VALUES: FRACTION MISSING\")\n",
    "for df in [CURRENT_YEAR]:\n",
    "    for col in df.columns:\n",
    "        if df[col].values.dtype != 'O':\n",
    "            frac_missing = np.mean(np.isnan(df[col].values))\n",
    "            if frac_missing > .1:\n",
    "                print(\"%s: %.2f\"%(col, frac_missing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the variables we don't want to standardize (labels & identifiers)\n",
    "carry_over_vars = [\"projid\", \"study\", \"fu_year\", \"scaled_to\", \"onset_label_time\", \"onset_label_time_binary\"]\n",
    "excluded_variables = [\"r_cistrk\", \"r_stroke\", \"lostcons\", \"chf_cum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll standardize this copy of the df\n",
    "new_ALL_YEARS = copy.copy(ALL_YEARS[carry_over_vars])\n",
    "new_CURRENT_YEAR = copy.copy(CURRENT_YEAR[carry_over_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous variables that need to be z-scored: \n",
    "cognitive_features = ['cts_animals', 'cts_bname', 'cts_catflu','cts_db', 'cts_delay', 'cts_df', 'cts_doperf', 'cts_ebdr', 'cts_ebmt',\\\n",
    "            'cts_fruits', 'cts_idea', 'cts_lopair', 'cts_mmse30', 'cts_nccrtd','cts_pmat', 'cts_pmsub', 'cts_read_nart', \\\n",
    "            'cts_sdmt', 'cts_story', 'cts_stroop_cname', 'cts_stroop_wread', 'cts_wli', 'cts_wlii', 'cts_wliii']\n",
    "medical_features_sums = ['med_con_sum_cum', 'vasc_3dis_sum', 'vasc_risks_sum']\n",
    "continuous_demographics = ['age_at_visit', 'educ']\n",
    "\n",
    "# Composite variables: average over z-scores from cognitive tests (\"cts_\" variables)\n",
    "composite_vars = {\n",
    "    \"cogn_ep\": [\"cts_wli\", \"cts_wlii\", \"cts_wliii\", \"cts_ebmt\", \"cts_ebdr\",  \"cts_story\",\"cts_delay\"],\n",
    "    \"cogn_po\": [\"cts_lopair\", \"cts_pmat\"],\n",
    "    \"cogn_ps\": [\"cts_sdmt\", \"cts_nccrtd\", \"cts_stroop_cname\", \"cts_stroop_wread\"],\n",
    "    \"cogn_se\":  [\"cts_bname\", \"cts_catflu\", \"cts_read_nart\"],\n",
    "    \"cogn_wo\": [\"cts_db\", \"cts_df\", \"cts_doperf\"],\n",
    "    \"cogn_global\":  [\"cts_wli\", \"cts_wlii\", \"cts_wliii\", \"cts_ebmt\", \"cts_ebdr\",  \"cts_story\",\"cts_delay\",\n",
    "                     \"cts_lopair\", \"cts_pmat\", \"cts_sdmt\", \"cts_nccrtd\", \"cts_stroop_cname\", \"cts_stroop_wread\",\n",
    "                     \"cts_bname\", \"cts_catflu\", \"cts_read_nart\", \"cts_db\", \"cts_df\", \"cts_doperf\"] }\n",
    "    \n",
    "# Binary variables: we leave these as is\n",
    "binary = ['hypertension_cum', 'cancer_cum','diabetes_sr_rx', 'dm_cum', 'headinjrloc_cum', 'lostcons',\\\n",
    "                         'thyroid_cum', 'chf_cum', 'claudication_cum', 'heart_cum', 'stroke_cum', \"msex\", \"spanish\"]\n",
    "\n",
    "# Categorical variables: need to be 1-hot encoded \n",
    "categorical = ['apoe_genotype', 'race', 'dcfdx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET DUMMIES FOR CATEGORICAL VARS\n",
    "temp = pd.concat((ALL_YEARS, CURRENT_YEAR))\n",
    "\n",
    "for feat in categorical:\n",
    "    dummies = pd.get_dummies(temp[feat])\n",
    "    for col in dummies.columns:\n",
    "        # if the column doesnt actually have any 1s for one of the datasets, don't add it\n",
    "        if (np.nansum(dummies.iloc[len(ALL_YEARS):][col]) > 0) and np.nansum(dummies.iloc[:len(ALL_YEARS)][col]) > 0:\n",
    "            new_ALL_YEARS[feat+\"__\"+str(col)] = dummies.iloc[:len(ALL_YEARS)][col]\n",
    "            new_CURRENT_YEAR[feat+\"__\"+str(col)]= dummies.iloc[len(ALL_YEARS):][col]\n",
    "            \n",
    "    new_ALL_YEARS.at[ALL_YEARS[feat].isnull(), new_ALL_YEARS.columns.str.startswith(feat)]=np.nan\n",
    "    new_CURRENT_YEAR.at[CURRENT_YEAR[feat].isnull(), new_CURRENT_YEAR.columns.str.startswith(feat)]=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get zscores for continuous vars\n",
    "zscore_transforms = {}\n",
    "\n",
    "for feat in cognitive_features + medical_features_sums + continuous_demographics:\n",
    "    if feat not in excluded_variables:\n",
    "        zscore_transforms[feat] = (np.nanmean(CURRENT_YEAR[feat]), np.nanstd(CURRENT_YEAR[feat]))\n",
    "    \n",
    "\n",
    "for feat in zscore_transforms.keys():\n",
    "    new_CURRENT_YEAR[feat] = (CURRENT_YEAR[feat]-zscore_transforms[feat][0])/zscore_transforms[feat][1]\n",
    "    new_ALL_YEARS[feat] = (ALL_YEARS[feat]-zscore_transforms[feat][0])/zscore_transforms[feat][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Given that we're saving z-scores, we want to save a file to revert back to raw values:\n",
    "#  un-standardize variables to get the original values:  x = (z*std)+mean\n",
    "f = open(new_folder+\"%iyrprev_within%i_mean_std.csv\"%(y,within),\"w\")\n",
    "f.write(\"variable, mean, std\\n\")\n",
    "for key, val in zscore_transforms.items():\n",
    "    f.write(\"%s, %f, %f\\n\"%(key, val[0], val[1]))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for comp in composite_vars:\n",
    "    vars_to_check = np.setdiff1d(composite_vars[comp], excluded_variables)\n",
    "    new_CURRENT_YEAR[comp] = new_CURRENT_YEAR[vars_to_check].mean(axis=1)\n",
    "    new_ALL_YEARS[comp] = new_ALL_YEARS[vars_to_check].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for b in binary:\n",
    "    if b not in excluded_variables:\n",
    "        new_CURRENT_YEAR[b] = CURRENT_YEAR[b]\n",
    "        new_ALL_YEARS[b] = ALL_YEARS[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARS WITH MISSING VALUES:\n",
      "24565\n",
      "onset_label_time 0.6294321188683085\n",
      "onset_label_time_binary 0.6294321188683085\n",
      "cts_pmat 0.11768776714838185\n",
      "cts_stroop_cname 0.5438225117036434\n",
      "cts_stroop_wread 0.5439853450030532\n",
      "9103\n",
      "cts_stroop_cname 0.6451719213446117\n",
      "cts_stroop_wread 0.6457211908162145\n"
     ]
    }
   ],
   "source": [
    "print(\"VARS WITH MISSING VALUES:\")\n",
    "for df in [new_ALL_YEARS, new_CURRENT_YEAR]:\n",
    "    print(len(df))\n",
    "    for col in df.columns:\n",
    "        if df[col].values.dtype != 'O':\n",
    "            frac_missing = np.mean(np.isnan(df[col].values))\n",
    "            if frac_missing > .1:\n",
    "                print(col, frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projid', 'study', 'fu_year', 'scaled_to', 'onset_label_time',\n",
       "       'onset_label_time_binary', 'apoe_genotype__22.0', 'apoe_genotype__23.0',\n",
       "       'apoe_genotype__24.0', 'apoe_genotype__33.0', 'apoe_genotype__34.0',\n",
       "       'apoe_genotype__44.0', 'race__1.0', 'race__2.0', 'race__3.0',\n",
       "       'race__6.0', 'dcfdx__1.0', 'dcfdx__2.0', 'dcfdx__3.0', 'cts_animals',\n",
       "       'cts_bname', 'cts_catflu', 'cts_db', 'cts_delay', 'cts_df',\n",
       "       'cts_doperf', 'cts_ebdr', 'cts_ebmt', 'cts_fruits', 'cts_idea',\n",
       "       'cts_lopair', 'cts_mmse30', 'cts_nccrtd', 'cts_pmat', 'cts_pmsub',\n",
       "       'cts_read_nart', 'cts_sdmt', 'cts_story', 'cts_stroop_cname',\n",
       "       'cts_stroop_wread', 'cts_wli', 'cts_wlii', 'cts_wliii',\n",
       "       'med_con_sum_cum', 'vasc_3dis_sum', 'vasc_risks_sum', 'age_at_visit',\n",
       "       'educ', 'cogn_ep', 'cogn_po', 'cogn_ps', 'cogn_se', 'cogn_wo',\n",
       "       'cogn_global', 'hypertension_cum', 'cancer_cum', 'diabetes_sr_rx',\n",
       "       'dm_cum', 'headinjrloc_cum', 'thyroid_cum', 'claudication_cum',\n",
       "       'heart_cum', 'stroke_cum', 'msex', 'spanish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_CURRENT_YEAR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24565, 65) (9103, 65)\n"
     ]
    }
   ],
   "source": [
    "print(new_ALL_YEARS.shape, new_CURRENT_YEAR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved standardized data sets to: \n",
      "../DATA/PROCESSED/standardized/merged_data_all_2yrprev_within3.csv\n",
      "../DATA/PROCESSED/standardized/merged_kept_data_2yrprev_within3.csv\n"
     ]
    }
   ],
   "source": [
    "new_ALL_YEARS.to_csv(new_folder + all_years_fname)\n",
    "new_CURRENT_YEAR.to_csv(new_folder + cur_year_fname)\n",
    "\n",
    "print(\"saved standardized data sets to: \\n%s\\n%s\"%(new_folder + all_years_fname, new_folder + cur_year_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
