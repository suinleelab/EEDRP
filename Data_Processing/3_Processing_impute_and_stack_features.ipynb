{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_folder =\"../DATA/PROCESSED/standardized/\"\n",
    "new_folder = \"../DATA/PROCESSED/standardized_stacked_imputed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = 2 # how many years in the past to collect data from\n",
    "file_suffix = str(years)+\"yrprev_within3\"\n",
    "DATA = pd.read_csv(os.path.join(orig_folder,\"merged_kept_data_%s.csv\"%file_suffix), index_col=0)\n",
    "DATA_all = pd.read_csv(os.path.join(orig_folder,\"merged_data_all_%s.csv\"%file_suffix), index_col=0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5fc2741a5afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDATA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA' is not defined"
     ]
    }
   ],
   "source": [
    "for col in DATA.columns[4:]:\n",
    "    if np.mean(np.isnan(DATA[col])) > 0:\n",
    "        print(col, np.mean(np.isnan(DATA[col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values (mean for continuous, mode for binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IF VARIABLE IS MISSING, USE MEAN IMPUTATION FOR CONTINUOUS VALS, MODE IMPUTATION FOR BINARY VALS:\n",
    "# these can stay as is\n",
    "binary = DATA.columns[[len(np.unique(DATA[c].dropna())) == 2 for c in DATA.columns]]\n",
    "\n",
    "impute_vals = {}\n",
    "\n",
    "\n",
    "for col in DATA.columns[4:]:\n",
    "    if col in binary:\n",
    "        impute_vals[col] = DATA[col].mode().values[0]\n",
    "    else:\n",
    "        impute_vals[col] = DATA[col].mean()\n",
    "\n",
    "    if np.mean(np.isnan(DATA[col])) > 0:\n",
    "        if col in binary:\n",
    "            # FILL WITH MOST COMMON:\n",
    "            DATA[col].fillna(DATA[col].mode().values[0], inplace=True)\n",
    "        else:\n",
    "            DATA[col].fillna(DATA[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = DATA.columns[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apoe_genotype__22.0', 'apoe_genotype__23.0', 'apoe_genotype__24.0',\n",
       "       'apoe_genotype__33.0', 'apoe_genotype__34.0', 'apoe_genotype__44.0',\n",
       "       'race__1.0', 'race__2.0', 'race__3.0', 'race__6.0', 'dcfdx__1.0',\n",
       "       'dcfdx__2.0', 'dcfdx__3.0', 'cts_animals', 'cts_bname', 'cts_catflu',\n",
       "       'cts_db', 'cts_delay', 'cts_df', 'cts_doperf', 'cts_ebdr', 'cts_ebmt',\n",
       "       'cts_fruits', 'cts_idea', 'cts_lopair', 'cts_mmse30', 'cts_nccrtd',\n",
       "       'cts_pmat', 'cts_pmsub', 'cts_read_nart', 'cts_sdmt', 'cts_story',\n",
       "       'cts_stroop_cname', 'cts_stroop_wread', 'cts_wli', 'cts_wlii',\n",
       "       'cts_wliii', 'med_con_sum_cum', 'vasc_3dis_sum', 'vasc_risks_sum',\n",
       "       'age_at_visit', 'educ', 'cogn_ep', 'cogn_po', 'cogn_ps', 'cogn_se',\n",
       "       'cogn_wo', 'cogn_global', 'hypertension_cum', 'cancer_cum',\n",
       "       'diabetes_sr_rx', 'dm_cum', 'headinjrloc_cum', 'thyroid_cum',\n",
       "       'claudication_cum', 'heart_cum', 'stroke_cum', 'msex', 'spanish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack matrices for each year (required for LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbbwang\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 of 9103\n",
      "2000 of 9103\n",
      "3000 of 9103\n",
      "4000 of 9103\n",
      "5000 of 9103\n",
      "6000 of 9103\n",
      "7000 of 9103\n",
      "8000 of 9103\n",
      "9000 of 9103\n"
     ]
    }
   ],
   "source": [
    "ALL_SAMPLES = DATA[[\"projid\", \"fu_year\", \"onset_label_time\", \"onset_label_time_binary\"]].values\n",
    "\n",
    "ALL_FEATURES_TIME = np.zeros([len(DATA), years+1, len(feature_names)])\n",
    "for i,row in DATA.iterrows():\n",
    "    if i%1000==0:\n",
    "        print(\"%i of %i\"%(i, len(DATA)))\n",
    "\n",
    "    for j,t in enumerate(range(years, 0, -1)):\n",
    "        pid_df = DATA_all[DATA_all[\"projid\"]==row[\"projid\"]]\n",
    "        \n",
    "        new_rows = pid_df[pid_df[\"fu_year\"].isin(row[\"fu_year\"]-np.arange(1,years+1))]\n",
    "\n",
    "        for col in new_rows.columns[new_rows.isnull().any()].tolist():\n",
    "            new_rows[col] = new_rows[col].fillna(impute_vals[col])\n",
    "        ALL_FEATURES_TIME[i,:-1,:] = new_rows[feature_names].values\n",
    "        \n",
    "    ALL_FEATURES_TIME[i,-1,:]=(row[feature_names].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9103, 3, 59)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_FEATURES_TIME.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "if not os.path.isdir(new_folder):\n",
    "    os.makedirs(new_folder)\n",
    "\n",
    "with h5py.File(os.path.join(new_folder,\"%s.h5\"%file_suffix), 'w') as hf:\n",
    "    hf.create_dataset(\"features\", data=ALL_FEATURES_TIME)\n",
    "    hf.create_dataset(\"samples\", data=ALL_SAMPLES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
