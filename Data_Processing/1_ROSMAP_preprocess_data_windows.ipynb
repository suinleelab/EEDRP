{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique patients:  3194\n"
     ]
    }
   ],
   "source": [
    "clin_df = pd.read_csv(\"../DATA/Raw/dataset_495_long.csv\")\n",
    "\n",
    "# specifically only reading in variables that are known pre-mortem\n",
    "static_df = pd.read_csv(\"../DATA/Raw/ROSMAP_clinical.csv\")[[\"projid\", \"msex\", \"educ\", \"apoe_genotype\", \"race\", \"spanish\"]]\n",
    " \n",
    "unique_projids = clin_df[\"projid\"].unique()\n",
    "print(\"# of unique patients: \", len(unique_projids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographics_df =  pd.read_csv(\"../DATA/Raw/dataset_495_basic.csv\")[[\"projid\", \"msex\", \"educ\", \"apoe_genotype\", \"race\", \"spanish\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clin_df = clin_df.merge(demographics_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set requirements:\n",
    "- min observations to keep a person in our dataset\n",
    "- for now, require that individuals start out with no dementia DX\n",
    "- another possibility: require people to start off with no dementia AND no MCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_ahead = 3\n",
    "require_previous = 2\n",
    "file_suffix = str(require_previous)+\"yrprev\" + \"_within%i\"%predict_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# current year + number of years ahead we want to be sure they don't get dementia + number of previous years\n",
    "min_obvs_neg = 1 + predict_ahead + require_previous\n",
    "# current year + next year (if they get dementia) + number of previous years\n",
    "min_obvs_pos = 1 + 1 + require_previous\n",
    "\n",
    "test_frac = .2\n",
    "cv_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174 individuals never receive a dementia diagnosis.\n",
      "557 individuals are given a dementia diagnosis during their time in the study.\n",
      "245 are excluded due to already having dementia\n"
     ]
    }
   ],
   "source": [
    "num_visits_list = np.array([len(clin_df[clin_df[\"projid\"] == pid]) for pid in unique_projids])\n",
    "projids = unique_projids[np.where(num_visits_list>=min_obvs_pos)[0]]\n",
    "\n",
    "\n",
    "no_eventual_dxs = []\n",
    "eventual_dxs = []\n",
    "excluded_already_dementia = []\n",
    "for projid in projids:\n",
    "    dxs = clin_df[clin_df[\"projid\"]==projid][\"dcfdx\"].values\n",
    "    # exclude people that get dementia before require_previous years have passed \n",
    "    if np.max(dxs[~np.isnan(dxs)][:require_previous+1]) > 3:\n",
    "        excluded_already_dementia.append(projid)\n",
    "    else:\n",
    "        # if they never get dementia AND have enough data to definitively know they wont in the next \"predict_ahead\" years:\n",
    "        if np.nanmax(dxs) <= 3 and len(dxs) >= min_obvs_neg:\n",
    "            no_eventual_dxs.append(projid)\n",
    "        elif np.nanmax(dxs) > 3:\n",
    "            eventual_dxs.append(projid)\n",
    "    \n",
    "\n",
    "print(\"%i individuals never receive a dementia diagnosis.\"%len(no_eventual_dxs))\n",
    "print(\"%i individuals are given a dementia diagnosis during their time in the study.\"%len(eventual_dxs))\n",
    "print(\"%i are excluded due to already having dementia\"%len(excluded_already_dementia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing onset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "fu_years_new = {}\n",
    "labels_time_to_dx = {}\n",
    "labels_binary = {}\n",
    "dcfdxs = {}\n",
    "\n",
    "for pid_i, projid in enumerate(projids):\n",
    "    if pid_i % 500 == 0:\n",
    "        print(pid_i)\n",
    "    \n",
    "    df = clin_df[clin_df[\"projid\"]==projid]\n",
    "    cur_fu_yrs = df[\"fu_year\"].values\n",
    "    dxes = df[\"dcfdx\"].values    \n",
    "    onset_label_times = []\n",
    "    onset_label_binaries = []\n",
    "\n",
    "    # look through all timepoints we have a row for\n",
    "    for t in cur_fu_yrs:\n",
    "\n",
    "        #####################################################################\n",
    "        ##### look at prior observations ####################################\n",
    "        #####################################################################\n",
    "        \n",
    "        # variable to check whether the input is valid (defaults to invalid)\n",
    "        valid_input = False\n",
    "        \n",
    "        # get indices for fu_years requried for current label\n",
    "        input_idxs = np.where(np.in1d(cur_fu_yrs, [t-x for x in range(require_previous+1)]))[0]\n",
    "\n",
    "        # check if they've ever been labeled with dementia before current observation\n",
    "        if np.nanmax(dxes[:np.max(input_idxs)+1]) > 3:\n",
    "            #if yes, then not a valid observation, since they've already had dementia\n",
    "            pass\n",
    "        # check if \"require_prev\" observations is satisfied -- need a label for each observation \n",
    "        elif len(input_idxs) == require_previous+1:\n",
    "            if np.mean(np.isnan(dxes[input_idxs])) == 0:\n",
    "                valid_input = True\n",
    "            # if this is shorter, then we dont have enough obsevations\n",
    "\n",
    "        #####################################################################\n",
    "        ##### look at future observations ###################################\n",
    "        #####################################################################\n",
    "            \n",
    "        # variable to see if we have a future label (defaults to no)\n",
    "        future_label = np.nan\n",
    "        \n",
    "        # years we want to see observations for\n",
    "        future_years =  [t+x for x in range(1, predict_ahead+1)]\n",
    "        # indices for which those yearly observations are located\n",
    "        future_idxs = np.where(np.in1d(cur_fu_yrs, future_years))[0]\n",
    "        # indices for which these yearly observations are located AND cognitive diagnosis is not nan\n",
    "        known_future_idxs = np.array(future_idxs)[~np.isnan(dxes[future_idxs])] \n",
    "\n",
    "        if len(known_future_idxs) > 0:\n",
    "            \n",
    "            # check to see if a dementia diagnosis was made\n",
    "            # if so, check how many years into the future the FIRST dementia diagnosis was made\n",
    "            if np.max(dxes[known_future_idxs]) > 3:\n",
    "                for f_id in known_future_idxs:\n",
    "                    if dxes[f_id]>3:\n",
    "                        onset_time = cur_fu_yrs[f_id]\n",
    "                        break\n",
    "                future_label = onset_time-t\n",
    "        \n",
    "            # if there is no AD diagnosis in the observed future years, \n",
    "            # we need to make sure we've seen \"no AD\" for EVERY future year (no missing values)\n",
    "            elif len(known_future_idxs) == predict_ahead:\n",
    "                future_label = 0 \n",
    "\n",
    "        #####################################################################\n",
    "        ##### Combine previous and future labels ############################\n",
    "        #####################################################################\n",
    "        \n",
    "        # in order to get an onset label (positive or negative), \n",
    "        # we need to have a valid # of prior observations, AND a valid future label\n",
    "        if valid_input==True and ~np.isnan(future_label):\n",
    "            onset_label_time = future_label\n",
    "            onset_label_binary = int(future_label>0)\n",
    "        else:\n",
    "            onset_label_time = np.nan\n",
    "            onset_label_binary = np.nan\n",
    "\n",
    "        onset_label_times.append(onset_label_time)\n",
    "        onset_label_binaries.append(onset_label_binary)\n",
    "\n",
    "\n",
    "    fu_years_new[projid] = cur_fu_yrs\n",
    "    labels_time_to_dx[projid] = onset_label_times\n",
    "    labels_binary[projid] = onset_label_binaries\n",
    "    dcfdxs[projid] = dxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pid_y_label_list_new = []\n",
    "for projid in projids:\n",
    "    for i in range(len(fu_years_new[projid])):\n",
    "        pid_y_label_list_new.append([projid, fu_years_new[projid][i], labels_time_to_dx[projid][i], labels_binary[projid][i]])\n",
    "valid_observations_new = pd.DataFrame(pid_y_label_list_new, columns=['projid', 'fu_year', 'onset_label_time', 'onset_label_time_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_obvs_new = clin_df.merge(valid_observations_new, on=[\"projid\", \"fu_year\"], how=\"left\")\n",
    "valid_obvs_new = all_obvs_new[~np.isnan(all_obvs_new[\"onset_label_time_binary\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savedir = \"../DATA/PROCESSED/\"\n",
    "if not os.path.isdir(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "\n",
    "# all samples with valid labels - plus current year's features\n",
    "valid_obvs_new.to_csv(os.path.join(savedir, \"merged_kept_data_%s.csv\"%file_suffix))\n",
    "# we also save all rows for samples with valid labels (we'll need features from past years for the samples we end up using)\n",
    "all_obvs_new.to_csv(os.path.join(savedir, \"merged_data_all_%s.csv\"%file_suffix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & test splits\n",
    "In order to avoid contamination, we pseudorandomly split samples into train/test splits:\n",
    "- all samples from a given individual must be in the same split\n",
    "- we separately split samples for people with (a) no eventual AD diagnosis, and (b) an eventual AD diagnosis so the fractions of each type of individual are balanced across CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_frac = .2\n",
    "cv_num = 5\n",
    "savedir = \"../DATA/PROCESSED/split_projids\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify all individuals with any valid observations --> get list of projids associated with people \n",
    "# who eventually get dementia (or dont)\n",
    "valid_pids = valid_obvs_new[\"projid\"].unique()\n",
    "eventual_dxs = [np.nanmax(valid_obvs_new[valid_obvs_new[\"projid\"]==pid][\"onset_label_time_binary\"]) for pid in valid_pids]\n",
    "no_eventual_dems = valid_pids[np.where(np.array(eventual_dxs)==0)]\n",
    "eventual_dems = valid_pids[np.where(np.array(eventual_dxs)==1)]\n",
    "\n",
    "\n",
    "## GENERATE SPLITS OF THE DATA: select test_frac individuals from the no dementia and dementia groups\n",
    "test_dem_idx = np.random.choice(eventual_dems, size=int(len(eventual_dems)*test_frac), replace=False)\n",
    "test_normal_idx = np.random.choice(no_eventual_dems, size=int(len(no_eventual_dems)*test_frac), replace=False)\n",
    "\n",
    "train_dem_idx = np.setdiff1d(eventual_dems, test_dem_idx)\n",
    "train_normal_idx = np.setdiff1d(no_eventual_dems, test_normal_idx)\n",
    "\n",
    "\n",
    "# save full training and test set\n",
    "if not os.path.isdir(savedir):\n",
    "    os.makedirs(savedir)\n",
    "np.savetxt(os.path.join(savedir, \"train_%s.txt\"%file_suffix), np.sort(np.union1d(train_dem_idx, train_normal_idx)), fmt=\"%s\")\n",
    "np.savetxt(os.path.join(savedir, \"test_%s.txt\"%file_suffix), np.sort(np.union1d(test_dem_idx, test_normal_idx)), fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For CV splits, shuffle the training sets and then divide it into cv_num groups\n",
    "rand_train_dem = np.random.permutation(train_dem_idx)\n",
    "rand_train_normal = np.random.permutation(train_normal_idx)\n",
    "\n",
    "chunksize_d = int(len(rand_train_dem)/cv_num)\n",
    "chunksize_n = int(len(rand_train_normal)/cv_num)\n",
    "\n",
    "CVsplits = []\n",
    "for i in range(cv_num):\n",
    "    cur_val_dem = rand_train_dem[i*chunksize_d: (1+i)*chunksize_d]\n",
    "    cur_val_normal = rand_train_normal[i*chunksize_n: (1+i)*chunksize_n]\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(savedir, \"CV_splits\", \"%i\"%i)):\n",
    "        os.makedirs(os.path.join(savedir, \"CV_splits\", \"%i\"%i))\n",
    "    \n",
    "    validation_to_save = np.sort(np.union1d(cur_val_dem, cur_val_normal))\n",
    "    train_to_save = np.sort(np.union1d(np.setdiff1d(train_dem_idx, cur_val_dem), np.setdiff1d(train_normal_idx, cur_val_normal)))\n",
    "    \n",
    "    np.savetxt(os.path.join(savedir, \"CV_splits\", \"%i\"%i, \"valid_%s.txt\"%file_suffix), validation_to_save, fmt=\"%s\")\n",
    "    np.savetxt(os.path.join(savedir, \"CV_splits\", \"%i\"%i, \"train_%s.txt\"%file_suffix), train_to_save, fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
